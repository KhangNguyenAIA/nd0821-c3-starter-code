[22:20:11] {train_model.py:42} INFO - [SUCCESS]: Load data
[22:21:01] {train_model.py:42} INFO - [SUCCESS]: Load data
[22:21:01] {train_model.py:91} INFO - Test Set Metrics:
[22:21:01] {train_model.py:92} INFO - Test precision: 0.7388
[22:21:01] {train_model.py:93} INFO - Test recall: 0.2505
[22:21:01] {train_model.py:94} INFO - Test fbeta: 0.3741

[22:21:02] {train_model.py:105} INFO - {'workclass:Private': {'precision': 0.7253731343283583, 'recall': 0.24203187250996017, 'fbeta': 0.362957430918596}, 'workclass:?': {'precision': 0.5555555555555556, 'recall': 0.2777777777777778, 'fbeta': 0.3703703703703704}, 'workclass:State-gov': {'precision': 0.8333333333333334, 'recall': 0.2054794520547945, 'fbeta': 0.3296703296703296}, 'workclass:Federal-gov': {'precision': 0.6363636363636364, 'recall': 0.23728813559322035, 'fbeta': 0.345679012345679}, 'workclass:Local-gov': {'precision': 0.6595744680851063, 'recall': 0.2108843537414966, 'fbeta': 0.31958762886597936}, 'workclass:Self-emp-not-inc': {'precision': 0.8095238095238095, 'recall': 0.2537313432835821, 'fbeta': 0.38636363636363635}, 'workclass:Self-emp-inc': {'precision': 0.9074074074074074, 'recall': 0.3828125, 'fbeta': 0.5384615384615384}, 'workclass:Without-pay': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'education:Assoc-acdm': {'precision': 0.8823529411764706, 'recall': 0.22727272727272727, 'fbeta': 0.3614457831325301}, 'education:11th': {'precision': 0.8571428571428571, 'recall': 0.5, 'fbeta': 0.631578947368421}, 'education:HS-grad': {'precision': 0.5655737704918032, 'recall': 0.21428571428571427, 'fbeta': 0.3108108108108108}, 'education:7th-8th': {'precision': 0.6, 'recall': 0.2727272727272727, 'fbeta': 0.37499999999999994}, 'education:Masters': {'precision': 0.8627450980392157, 'recall': 0.24043715846994534, 'fbeta': 0.37606837606837606}, 'education:Some-college': {'precision': 0.6276595744680851, 'recall': 0.21691176470588236, 'fbeta': 0.3224043715846995}, 'education:1st-4th': {'precision': 1.0, 'recall': 0.5, 'fbeta': 0.6666666666666666}, 'education:Assoc-voc': {'precision': 0.6538461538461539, 'recall': 0.22077922077922077, 'fbeta': 0.3300970873786408}, 'education:Doctorate': {'precision': 0.9565217391304348, 'recall': 0.36065573770491804, 'fbeta': 0.5238095238095238}, 'education:Bachelors': {'precision': 0.8601398601398601, 'recall': 0.265658747300216, 'fbeta': 0.40594059405940597}, 'education:5th-6th': {'precision': 0.5, 'recall': 0.25, 'fbeta': 0.3333333333333333}, 'education:Prof-school': {'precision': 0.9714285714285714, 'recall': 0.4, 'fbeta': 0.5666666666666667}, 'education:10th': {'precision': 0.2, 'recall': 0.07692307692307693, 'fbeta': 0.1111111111111111}, 'education:9th': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'education:12th': {'precision': 0.3333333333333333, 'recall': 0.2, 'fbeta': 0.25}, 'education:Preschool': {'precision': 0.0, 'recall': 1.0, 'fbeta': 0.0}, 'marital-status:Divorced': {'precision': 0.6382978723404256, 'recall': 0.38461538461538464, 'fbeta': 0.48000000000000004}, 'marital-status:Married-civ-spouse': {'precision': 0.8496042216358839, 'recall': 0.2348650619985412, 'fbeta': 0.36799999999999994}, 'marital-status:Never-married': {'precision': 0.3888888888888889, 'recall': 0.35, 'fbeta': 0.36842105263157887}, 'marital-status:Married-spouse-absent': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'marital-status:Separated': {'precision': 0.6666666666666666, 'recall': 0.46153846153846156, 'fbeta': 0.5454545454545455}, 'marital-status:Widowed': {'precision': 0.375, 'recall': 0.25, 'fbeta': 0.3}, 'marital-status:Married-AF-spouse': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'occupation:Tech-support': {'precision': 0.6, 'recall': 0.19148936170212766, 'fbeta': 0.29032258064516125}, 'occupation:Machine-op-inspct': {'precision': 0.5882352941176471, 'recall': 0.22727272727272727, 'fbeta': 0.32786885245901637}, 'occupation:Adm-clerical': {'precision': 0.3953488372093023, 'recall': 0.18478260869565216, 'fbeta': 0.2518518518518518}, 'occupation:Craft-repair': {'precision': 0.6923076923076923, 'recall': 0.22842639593908629, 'fbeta': 0.3435114503816794}, 'occupation:?': {'precision': 0.5555555555555556, 'recall': 0.2777777777777778, 'fbeta': 0.3703703703703704}, 'occupation:Farming-fishing': {'precision': 0.6153846153846154, 'recall': 0.2962962962962963, 'fbeta': 0.4}, 'occupation:Exec-managerial': {'precision': 0.9193548387096774, 'recall': 0.2733812949640288, 'fbeta': 0.42144177449168213}, 'occupation:Sales': {'precision': 0.7678571428571429, 'recall': 0.225130890052356, 'fbeta': 0.3481781376518219}, 'occupation:Prof-specialty': {'precision': 0.84375, 'recall': 0.2967032967032967, 'fbeta': 0.43902439024390244}, 'occupation:Transport-moving': {'precision': 0.7272727272727273, 'recall': 0.24242424242424243, 'fbeta': 0.36363636363636365}, 'occupation:Other-service': {'precision': 0.3125, 'recall': 0.1724137931034483, 'fbeta': 0.22222222222222224}, 'occupation:Protective-serv': {'precision': 0.8333333333333334, 'recall': 0.1724137931034483, 'fbeta': 0.28571428571428575}, 'occupation:Handlers-cleaners': {'precision': 0.14285714285714285, 'recall': 0.07692307692307693, 'fbeta': 0.1}, 'occupation:Priv-house-serv': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'relationship:Not-in-family': {'precision': 0.5192307692307693, 'recall': 0.3333333333333333, 'fbeta': 0.40601503759398494}, 'relationship:Husband': {'precision': 0.8593272171253823, 'recall': 0.230327868852459, 'fbeta': 0.3632837750484809}, 'relationship:Unmarried': {'precision': 0.5217391304347826, 'recall': 0.375, 'fbeta': 0.43636363636363634}, 'relationship:Own-child': {'precision': 0.16, 'recall': 0.3076923076923077, 'fbeta': 0.2105263157894737}, 'relationship:Other-relative': {'precision': 0.7, 'recall': 0.7, 'fbeta': 0.7}, 'relationship:Wife': {'precision': 0.8085106382978723, 'recall': 0.2638888888888889, 'fbeta': 0.39790575916230364}, 'race:White': {'precision': 0.7526427061310782, 'recall': 0.25176803394625175, 'fbeta': 0.37731849496555375}, 'race:Amer-Indian-Eskimo': {'precision': 0.75, 'recall': 0.3333333333333333, 'fbeta': 0.46153846153846156}, 'race:Black': {'precision': 0.5625, 'recall': 0.20930232558139536, 'fbeta': 0.30508474576271183}, 'race:Other': {'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'fbeta': 0.5333333333333333}, 'race:Asian-Pac-Islander': {'precision': 0.7142857142857143, 'recall': 0.23809523809523808, 'fbeta': 0.35714285714285715}, 'sex:Female': {'precision': 0.5254237288135594, 'recall': 0.29245283018867924, 'fbeta': 0.3757575757575758}, 'sex:Male': {'precision': 0.7990430622009569, 'recall': 0.24397370343316288, 'fbeta': 0.3738108561835478}, 'native-country:United-States': {'precision': 0.7474949899799599, 'recall': 0.25848925848925847, 'fbeta': 0.384140061791967}, 'native-country:Mexico': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Greece': {'precision': 0.5, 'recall': 1.0, 'fbeta': 0.6666666666666666}, 'native-country:Canada': {'precision': 0.5, 'recall': 0.14285714285714285, 'fbeta': 0.22222222222222224}, 'native-country:?': {'precision': 0.8333333333333334, 'recall': 0.20833333333333334, 'fbeta': 0.33333333333333337}, 'native-country:Portugal': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:El-Salvador': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:China': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Vietnam': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Germany': {'precision': 1.0, 'recall': 0.09090909090909091, 'fbeta': 0.16666666666666669}, 'native-country:Philippines': {'precision': 0.5, 'recall': 0.14285714285714285, 'fbeta': 0.22222222222222224}, 'native-country:Italy': {'precision': 1.0, 'recall': 0.25, 'fbeta': 0.4}, 'native-country:Cuba': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:England': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Ireland': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Jamaica': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Nicaragua': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Haiti': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:India': {'precision': 1.0, 'recall': 0.2857142857142857, 'fbeta': 0.4444444444444445}, 'native-country:Japan': {'precision': 1.0, 'recall': 0.25, 'fbeta': 0.4}, 'native-country:Cambodia': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Laos': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Puerto-Rico': {'precision': 0.5, 'recall': 1.0, 'fbeta': 0.6666666666666666}, 'native-country:Taiwan': {'precision': 1.0, 'recall': 0.16666666666666666, 'fbeta': 0.2857142857142857}, 'native-country:Poland': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Dominican-Republic': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Iran': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'fbeta': 0.6666666666666666}, 'native-country:Columbia': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Honduras': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Yugoslavia': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:France': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Guatemala': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Trinadad&Tobago': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Peru': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:South': {'precision': 0.5, 'recall': 0.5, 'fbeta': 0.5}, 'native-country:Ecuador': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Thailand': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Hong': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Outlying-US(Guam-USVI-etc)': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Hungary': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Scotland': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}}
[14:30:56] {train_model.py:42} INFO - [SUCCESS]: Load data
[14:30:56] {train_model.py:91} INFO - Test Set Metrics:
[14:30:56] {train_model.py:92} INFO - Test precision: 0.7101
[14:30:56] {train_model.py:93} INFO - Test recall: 0.2635
[14:30:56] {train_model.py:94} INFO - Test fbeta: 0.3844

[14:30:57] {train_model.py:107} INFO - {'workclass:Private': {'precision': 0.6758241758241759, 'recall': 0.2520491803278688, 'fbeta': 0.3671641791044776}, 'workclass:State-gov': {'precision': 0.75, 'recall': 0.25, 'fbeta': 0.375}, 'workclass:Federal-gov': {'precision': 0.6666666666666666, 'recall': 0.2, 'fbeta': 0.30769230769230765}, 'workclass:Local-gov': {'precision': 0.7941176470588235, 'recall': 0.22131147540983606, 'fbeta': 0.34615384615384615}, 'workclass:?': {'precision': 0.5, 'recall': 0.30303030303030304, 'fbeta': 0.37735849056603776}, 'workclass:Self-emp-inc': {'precision': 0.9032258064516129, 'recall': 0.43410852713178294, 'fbeta': 0.5863874345549738}, 'workclass:Self-emp-not-inc': {'precision': 0.75, 'recall': 0.2571428571428571, 'fbeta': 0.3829787234042553}, 'workclass:Without-pay': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'workclass:Never-worked': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'education:Some-college': {'precision': 0.5803571428571429, 'recall': 0.23636363636363636, 'fbeta': 0.3359173126614987}, 'education:Assoc-acdm': {'precision': 0.8421052631578947, 'recall': 0.25806451612903225, 'fbeta': 0.3950617283950617}, 'education:Masters': {'precision': 0.9285714285714286, 'recall': 0.2639593908629442, 'fbeta': 0.41106719367588934}, 'education:5th-6th': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'education:HS-grad': {'precision': 0.5338345864661654, 'recall': 0.2191358024691358, 'fbeta': 0.31072210065645517}, 'education:Bachelors': {'precision': 0.825503355704698, 'recall': 0.2935560859188544, 'fbeta': 0.43309859154929575}, 'education:7th-8th': {'precision': 0.3333333333333333, 'recall': 0.1111111111111111, 'fbeta': 0.16666666666666666}, 'education:Assoc-voc': {'precision': 0.68, 'recall': 0.2328767123287671, 'fbeta': 0.3469387755102041}, 'education:11th': {'precision': 0.7142857142857143, 'recall': 0.45454545454545453, 'fbeta': 0.5555555555555556}, 'education:12th': {'precision': 0.5, 'recall': 0.25, 'fbeta': 0.3333333333333333}, 'education:9th': {'precision': 1.0, 'recall': 0.3333333333333333, 'fbeta': 0.5}, 'education:Doctorate': {'precision': 1.0, 'recall': 0.3275862068965517, 'fbeta': 0.49350649350649356}, 'education:Prof-school': {'precision': 0.8918918918918919, 'recall': 0.3473684210526316, 'fbeta': 0.5000000000000001}, 'education:1st-4th': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'education:10th': {'precision': 0.5, 'recall': 0.26666666666666666, 'fbeta': 0.3478260869565218}, 'education:Preschool': {'precision': 0.0, 'recall': 1.0, 'fbeta': 0.0}, 'marital-status:Never-married': {'precision': 0.4020618556701031, 'recall': 0.4020618556701031, 'fbeta': 0.4020618556701031}, 'marital-status:Married-civ-spouse': {'precision': 0.8226600985221675, 'recall': 0.2511278195488722, 'fbeta': 0.3847926267281106}, 'marital-status:Separated': {'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'fbeta': 0.4}, 'marital-status:Divorced': {'precision': 0.5, 'recall': 0.2808988764044944, 'fbeta': 0.3597122302158274}, 'marital-status:Married-spouse-absent': {'precision': 1.0, 'recall': 0.5, 'fbeta': 0.6666666666666666}, 'marital-status:Widowed': {'precision': 0.3333333333333333, 'recall': 0.3125, 'fbeta': 0.3225806451612903}, 'marital-status:Married-AF-spouse': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'occupation:Craft-repair': {'precision': 0.6166666666666667, 'recall': 0.21142857142857144, 'fbeta': 0.31489361702127666}, 'occupation:Farming-fishing': {'precision': 0.6363636363636364, 'recall': 0.3333333333333333, 'fbeta': 0.43749999999999994}, 'occupation:Other-service': {'precision': 0.3076923076923077, 'recall': 0.22857142857142856, 'fbeta': 0.26229508196721313}, 'occupation:Prof-specialty': {'precision': 0.8347107438016529, 'recall': 0.2707774798927614, 'fbeta': 0.40890688259109315}, 'occupation:Machine-op-inspct': {'precision': 0.4117647058823529, 'recall': 0.15555555555555556, 'fbeta': 0.22580645161290322}, 'occupation:Protective-serv': {'precision': 0.6, 'recall': 0.15789473684210525, 'fbeta': 0.25}, 'occupation:Exec-managerial': {'precision': 0.9271523178807947, 'recall': 0.35175879396984927, 'fbeta': 0.5100182149362477}, 'occupation:Sales': {'precision': 0.7096774193548387, 'recall': 0.22916666666666666, 'fbeta': 0.3464566929133858}, 'occupation:?': {'precision': 0.5, 'recall': 0.30303030303030304, 'fbeta': 0.37735849056603776}, 'occupation:Tech-support': {'precision': 0.45454545454545453, 'recall': 0.09433962264150944, 'fbeta': 0.15625}, 'occupation:Transport-moving': {'precision': 0.625, 'recall': 0.20833333333333334, 'fbeta': 0.3125}, 'occupation:Adm-clerical': {'precision': 0.46153846153846156, 'recall': 0.2376237623762376, 'fbeta': 0.3137254901960784}, 'occupation:Priv-house-serv': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'occupation:Handlers-cleaners': {'precision': 0.45454545454545453, 'recall': 0.3333333333333333, 'fbeta': 0.3846153846153846}, 'occupation:Armed-Forces': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'relationship:Own-child': {'precision': 0.13333333333333333, 'recall': 0.4444444444444444, 'fbeta': 0.20512820512820512}, 'relationship:Husband': {'precision': 0.834733893557423, 'recall': 0.2531860662701784, 'fbeta': 0.38852672750977835}, 'relationship:Wife': {'precision': 0.75, 'recall': 0.22602739726027396, 'fbeta': 0.34736842105263155}, 'relationship:Unmarried': {'precision': 0.4857142857142857, 'recall': 0.40476190476190477, 'fbeta': 0.4415584415584416}, 'relationship:Not-in-family': {'precision': 0.5098039215686274, 'recall': 0.3076923076923077, 'fbeta': 0.3837638376383764}, 'relationship:Other-relative': {'precision': 0.625, 'recall': 0.5555555555555556, 'fbeta': 0.5882352941176471}, 'race:White': {'precision': 0.7212475633528265, 'recall': 0.2644746247319514, 'fbeta': 0.38702928870292885}, 'race:Black': {'precision': 0.5806451612903226, 'recall': 0.21951219512195122, 'fbeta': 0.31858407079646023}, 'race:Amer-Indian-Eskimo': {'precision': 0.6666666666666666, 'recall': 0.5, 'fbeta': 0.5714285714285715}, 'race:Other': {'precision': 0.6666666666666666, 'recall': 0.4, 'fbeta': 0.5}, 'race:Asian-Pac-Islander': {'precision': 0.65, 'recall': 0.24528301886792453, 'fbeta': 0.35616438356164376}, 'sex:Male': {'precision': 0.7711111111111111, 'recall': 0.26129518072289154, 'fbeta': 0.390326209223847}, 'sex:Female': {'precision': 0.49206349206349204, 'recall': 0.2767857142857143, 'fbeta': 0.3542857142857143}, 'native-country:United-States': {'precision': 0.7171903881700554, 'recall': 0.2709497206703911, 'fbeta': 0.39330968068930566}, 'native-country:Mexico': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:?': {'precision': 0.8, 'recall': 0.2962962962962963, 'fbeta': 0.43243243243243246}, 'native-country:South': {'precision': 0.5, 'recall': 0.5, 'fbeta': 0.5}, 'native-country:Philippines': {'precision': 1.0, 'recall': 0.18181818181818182, 'fbeta': 0.3076923076923077}, 'native-country:Dominican-Republic': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:El-Salvador': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Canada': {'precision': 0.8333333333333334, 'recall': 0.45454545454545453, 'fbeta': 0.5882352941176471}, 'native-country:Iran': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Taiwan': {'precision': 0.5, 'recall': 0.16666666666666666, 'fbeta': 0.25}, 'native-country:Laos': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Peru': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Vietnam': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Ireland': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:England': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Cambodia': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:India': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Cuba': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Jamaica': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:France': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Honduras': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Thailand': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:China': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Puerto-Rico': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Poland': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Guatemala': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Italy': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Haiti': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Germany': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Hungary': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Scotland': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Japan': {'precision': 0.6666666666666666, 'recall': 0.3333333333333333, 'fbeta': 0.4444444444444444}, 'native-country:Hong': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Columbia': {'precision': 0.0, 'recall': 1.0, 'fbeta': 0.0}, 'native-country:Portugal': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Outlying-US(Guam-USVI-etc)': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Yugoslavia': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Greece': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Trinadad&Tobago': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Ecuador': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Nicaragua': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Holand-Netherlands': {'precision': 0.0, 'recall': 1.0, 'fbeta': 0.0}}
[21:30:09] {train_model.py:42} INFO - [SUCCESS]: Load data
[21:30:09] {train_model.py:94} INFO - Test Set Metrics:
[21:30:09] {train_model.py:95} INFO - Test precision: 0.7140
[21:30:09] {train_model.py:96} INFO - Test recall: 0.2532
[21:30:09] {train_model.py:97} INFO - Test fbeta: 0.3738

[21:30:10] {train_model.py:110} INFO - {'workclass:Private': {'precision': 0.6821917808219178, 'recall': 0.24127906976744187, 'fbeta': 0.35647816750178957}, 'workclass:?': {'precision': 0.5263157894736842, 'recall': 0.24390243902439024, 'fbeta': 0.3333333333333333}, 'workclass:Self-emp-not-inc': {'precision': 0.7818181818181819, 'recall': 0.2925170068027211, 'fbeta': 0.42574257425742573}, 'workclass:Federal-gov': {'precision': 0.6774193548387096, 'recall': 0.23595505617977527, 'fbeta': 0.35}, 'workclass:State-gov': {'precision': 0.9, 'recall': 0.27692307692307694, 'fbeta': 0.42352941176470593}, 'workclass:Local-gov': {'precision': 0.6666666666666666, 'recall': 0.2153846153846154, 'fbeta': 0.3255813953488372}, 'workclass:Self-emp-inc': {'precision': 0.9230769230769231, 'recall': 0.3356643356643357, 'fbeta': 0.4923076923076924}, 'workclass:Never-worked': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'education:11th': {'precision': 0.3333333333333333, 'recall': 0.6, 'fbeta': 0.42857142857142855}, 'education:HS-grad': {'precision': 0.5702479338842975, 'recall': 0.20116618075801748, 'fbeta': 0.29741379310344823}, 'education:Masters': {'precision': 0.9102564102564102, 'recall': 0.355, 'fbeta': 0.5107913669064748}, 'education:Some-college': {'precision': 0.6530612244897959, 'recall': 0.2140468227424749, 'fbeta': 0.3224181360201511}, 'education:Bachelors': {'precision': 0.7714285714285715, 'recall': 0.2363238512035011, 'fbeta': 0.3618090452261306}, 'education:Prof-school': {'precision': 0.925, 'recall': 0.37373737373737376, 'fbeta': 0.5323741007194245}, 'education:Preschool': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'education:7th-8th': {'precision': 0.3333333333333333, 'recall': 0.2857142857142857, 'fbeta': 0.30769230769230765}, 'education:Assoc-acdm': {'precision': 0.68, 'recall': 0.27419354838709675, 'fbeta': 0.39080459770114945}, 'education:Assoc-voc': {'precision': 0.7037037037037037, 'recall': 0.24358974358974358, 'fbeta': 0.3619047619047619}, 'education:10th': {'precision': 0.5454545454545454, 'recall': 0.35294117647058826, 'fbeta': 0.42857142857142855}, 'education:9th': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'fbeta': 0.3333333333333333}, 'education:12th': {'precision': 0.5, 'recall': 0.2, 'fbeta': 0.28571428571428575}, 'education:5th-6th': {'precision': 0.25, 'recall': 1.0, 'fbeta': 0.4}, 'education:Doctorate': {'precision': 0.9444444444444444, 'recall': 0.265625, 'fbeta': 0.4146341463414634}, 'education:1st-4th': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'marital-status:Married-civ-spouse': {'precision': 0.819047619047619, 'recall': 0.24328147100424327, 'fbeta': 0.3751363140676118}, 'marital-status:Divorced': {'precision': 0.5084745762711864, 'recall': 0.2912621359223301, 'fbeta': 0.3703703703703703}, 'marital-status:Never-married': {'precision': 0.34615384615384615, 'recall': 0.313953488372093, 'fbeta': 0.32926829268292684}, 'marital-status:Separated': {'precision': 0.5833333333333334, 'recall': 0.4375, 'fbeta': 0.5}, 'marital-status:Married-spouse-absent': {'precision': 0.5, 'recall': 0.25, 'fbeta': 0.3333333333333333}, 'marital-status:Widowed': {'precision': 0.6666666666666666, 'recall': 0.375, 'fbeta': 0.4800000000000001}, 'marital-status:Married-AF-spouse': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'occupation:Other-service': {'precision': 0.3, 'recall': 0.3157894736842105, 'fbeta': 0.3076923076923077}, 'occupation:Craft-repair': {'precision': 0.6515151515151515, 'recall': 0.21182266009852216, 'fbeta': 0.31970260223048325}, 'occupation:?': {'precision': 0.5263157894736842, 'recall': 0.24390243902439024, 'fbeta': 0.3333333333333333}, 'occupation:Transport-moving': {'precision': 0.5714285714285714, 'recall': 0.2222222222222222, 'fbeta': 0.32}, 'occupation:Tech-support': {'precision': 0.7619047619047619, 'recall': 0.24242424242424243, 'fbeta': 0.367816091954023}, 'occupation:Sales': {'precision': 0.7108433734939759, 'recall': 0.295, 'fbeta': 0.4169611307420495}, 'occupation:Farming-fishing': {'precision': 0.7272727272727273, 'recall': 0.4, 'fbeta': 0.5161290322580645}, 'occupation:Prof-specialty': {'precision': 0.8214285714285714, 'recall': 0.2875, 'fbeta': 0.42592592592592593}, 'occupation:Adm-clerical': {'precision': 0.4634146341463415, 'recall': 0.1792452830188679, 'fbeta': 0.2585034013605442}, 'occupation:Machine-op-inspct': {'precision': 0.4074074074074074, 'recall': 0.20754716981132076, 'fbeta': 0.275}, 'occupation:Protective-serv': {'precision': 0.7142857142857143, 'recall': 0.10416666666666667, 'fbeta': 0.18181818181818182}, 'occupation:Handlers-cleaners': {'precision': 0.36363636363636365, 'recall': 0.26666666666666666, 'fbeta': 0.30769230769230765}, 'occupation:Exec-managerial': {'precision': 0.9316239316239316, 'recall': 0.25829383886255924, 'fbeta': 0.4044526901669759}, 'occupation:Priv-house-serv': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'relationship:Wife': {'precision': 0.7674418604651163, 'recall': 0.19298245614035087, 'fbeta': 0.30841121495327106}, 'relationship:Husband': {'precision': 0.8252688172043011, 'recall': 0.24878444084278767, 'fbeta': 0.38231631382316317}, 'relationship:Not-in-family': {'precision': 0.49107142857142855, 'recall': 0.3216374269005848, 'fbeta': 0.38869257950530034}, 'relationship:Own-child': {'precision': 0.2727272727272727, 'recall': 0.42857142857142855, 'fbeta': 0.33333333333333326}, 'relationship:Other-relative': {'precision': 0.5, 'recall': 0.16666666666666666, 'fbeta': 0.25}, 'relationship:Unmarried': {'precision': 0.45454545454545453, 'recall': 0.29411764705882354, 'fbeta': 0.35714285714285715}, 'race:White': {'precision': 0.7310606060606061, 'recall': 0.25716189207195206, 'fbeta': 0.38048299655002465}, 'race:Black': {'precision': 0.5, 'recall': 0.2236842105263158, 'fbeta': 0.3090909090909091}, 'race:Asian-Pac-Islander': {'precision': 0.6666666666666666, 'recall': 0.17543859649122806, 'fbeta': 0.2777777777777778}, 'race:Amer-Indian-Eskimo': {'precision': 0.4, 'recall': 0.4, 'fbeta': 0.4000000000000001}, 'race:Other': {'precision': 1.0, 'recall': 0.25, 'fbeta': 0.4}, 'sex:Female': {'precision': 0.512, 'recall': 0.24521072796934865, 'fbeta': 0.3316062176165803}, 'sex:Male': {'precision': 0.7690631808278867, 'recall': 0.2546897546897547, 'fbeta': 0.38265582655826563}, 'native-country:United-States': {'precision': 0.7171903881700554, 'recall': 0.2554312047399605, 'fbeta': 0.37669902912621356}, 'native-country:China': {'precision': 0.5, 'recall': 0.2857142857142857, 'fbeta': 0.36363636363636365}, 'native-country:El-Salvador': {'precision': 0.5, 'recall': 0.3333333333333333, 'fbeta': 0.4}, 'native-country:?': {'precision': 0.7777777777777778, 'recall': 0.28, 'fbeta': 0.4117647058823529}, 'native-country:Trinadad&Tobago': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Ireland': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Philippines': {'precision': 0.5, 'recall': 0.11764705882352941, 'fbeta': 0.19047619047619047}, 'native-country:Canada': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Hong': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:India': {'precision': 1.0, 'recall': 0.125, 'fbeta': 0.2222222222222222}, 'native-country:Mexico': {'precision': 0.6666666666666666, 'recall': 0.5, 'fbeta': 0.5714285714285715}, 'native-country:Puerto-Rico': {'precision': 1.0, 'recall': 0.5, 'fbeta': 0.6666666666666666}, 'native-country:Poland': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Germany': {'precision': 1.0, 'recall': 0.23076923076923078, 'fbeta': 0.375}, 'native-country:Guatemala': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Portugal': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Ecuador': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Japan': {'precision': 1.0, 'recall': 0.3333333333333333, 'fbeta': 0.5}, 'native-country:Peru': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Italy': {'precision': 1.0, 'recall': 0.3333333333333333, 'fbeta': 0.5}, 'native-country:Greece': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Dominican-Republic': {'precision': 0.0, 'recall': 1.0, 'fbeta': 0.0}, 'native-country:Iran': {'precision': 1.0, 'recall': 0.2, 'fbeta': 0.33333333333333337}, 'native-country:Haiti': {'precision': 0.0, 'recall': 1.0, 'fbeta': 0.0}, 'native-country:Hungary': {'precision': 0.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Taiwan': {'precision': 1.0, 'recall': 0.5, 'fbeta': 0.6666666666666666}, 'native-country:France': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:South': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:England': {'precision': 1.0, 'recall': 0.125, 'fbeta': 0.2222222222222222}, 'native-country:Outlying-US(Guam-USVI-etc)': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Cuba': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Columbia': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Jamaica': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Nicaragua': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Scotland': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Vietnam': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Laos': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Cambodia': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}, 'native-country:Honduras': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Thailand': {'precision': 1.0, 'recall': 1.0, 'fbeta': 1.0}, 'native-country:Yugoslavia': {'precision': 1.0, 'recall': 0.0, 'fbeta': 0.0}}
